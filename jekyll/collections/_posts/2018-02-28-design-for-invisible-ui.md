---
title: ‘Zero-UI’ Design for voice and invisible UI
author:
  - Shannon Young
date: 2018-02-28T16:56:09+00:00
url: /design-for-invisible-ui/
featured_image: "2018/design-for-invisible-ui"
featured_image_alt: "Soundwave from Smart speakers and virtual assistants"
categories: fun
tags:
  - Brand
  - creativity
  - design
  - Smart Speakers
  - structured data
  - UI/UX
  - Virtual Assistant
  - voice
---
**It’s most likely you have heard of them, or heard stories about them*. Possibly you even own one! (I personally don’t trust them. More on that later.)**
<!--more-->

## Smart speakers and virtual assistants


> Awareness of voice-activated speakers is increasing; over half of GB adults claim to know a little bit about them. However, ownership is still low; 5% currently own a voice activated speaker and just 10% of non owners are likely to buy in the next 12 months.
  
> – Source: [Ipsos connect techtracker Q4 2017][1]

They both have one thing in common, they are devices that are always on, always listening, waiting for your voice commands which usually are initiated with ‘wake/action words’ such as “Alexa”, “Ok Google” or anything GCHQ deem to warrant putting you on some list.

  * [A T.V commercial made my Alexa order cat food.][2]
  * [Apple HomePod is staining my wooden table.][3]
  * [Should an Amazon Echo Help Solve a Murder?][4]
  * [Amazon promises fix for creepy Alexa laugh][5]

### Top playas

**Google
  
** Virtual assistant: Google Assistant (now available on fridges)
  
Smart speaker: Google Home

**Apple**
  
Virtual assistant: Siri
  
Smart speaker: HomePod

**Microsoft**
  
Virtual assistant: Cortana
  
Smart speaker: Microsoft’s Harman Kardon Invoke

**Amazon**
  
Virtual assistant: Alexa
  
Smart speaker: Echo

Please god, don’t let Facebo&#8230;

> Facebook is reportedly releasing two smart speakers later this year to compete with the Amazon Echo. The two devices, apparently codenamed “Fiona” and “Aloha,” could be released as early as July 2018.
  
> – Source: [The Next Web][6]

&#8230;ah. Well, there you go.

### How we interact

<img class="alignnone wp-image-12872 size-full" src="https://www.mark-making.com/wp-content/uploads/2018/02/1000x450_VoiceActive.jpg" alt="Waveform" width="1000" height="400"  />

Because we use voices, our interactions with these devices are naturally different from, for example, using a search engine. Queries are more conversational and we speak to them as if we are interacting with another human:

  * I want to go on a holiday.
  * I want some Sushi, where is the nearest place?
  * What Nikes should I buy?

The device that was listening to your conversation before now actually has a query that requires action, they do this using what’s known as natural language processing (NLP).

> Almost 70% of requests to Google Assistant are expressed in natural language, not the typical keywords people type in a web search. And many requests are follow-ups that continue an ongoing conversation.
  
> – Source: [Google][7]

Natural language processing (NLP) can be defined as the ability of a machine to analyse, understand, and generate human speech. The goal of NLP is to make interactions between computers and humans feel exactly like interactions between humans and humans.

Aside from listening to music and shopping, most users are controlling [internet-of-things-connected][8] devices.

  * Turn off the lights in the kitchen.
  * Set the heating 2 degrees higher.

Among other things, we want them to tell us a joke:

<img class="alignnone wp-image-12867 size-full" src="https://www.mark-making.com/wp-content/uploads/2018/02/voice-ai-rekt-2.png" alt="Google jokes." width="365" height="243"  />

**Attitudes towards voice-activated speakers**

I’m not the only one with privacy concerns around these devices. 1 in 3 adults in the UK worry about conversations being recorded and 1 in 4 feel uncomfortable talking to a machine. [1]
  
19% of Americans who own one keep the assistant in their master bedroom, let’s hope your partner is not called Alexa [2].

### Designing the invisible

> The total number of voice assistant devices will reach 870 million in the U.S. by 2022 – a 95 percent increase from the total of 450 million estimated for 2017.
  
> – Source: [Techcrunch][9]

### What is zero UI?

Zero-UI is the concept of abstracting away the interface that exists between user and device, so the experience becomes a more seamless interaction with the technology.

> The real problem with the interface is that it is an interface. Interfaces get in the way.
  
> – Donald Norman, 1990

Designers for voice need to put themselves into the shoes of the user, take into account principles of social interactions and user intent, then apply brand personality. The concept of tone of voice has expanded to incorporate other aspects of a brand’s principles and behavior, from the jokes it makes to the emojis it uses. Now we’re in the realm of user experience design, around conversational UI (but without the interface).

<img class="alignnone wp-image-12873 size-full" src="https://www.mark-making.com/wp-content/uploads/2018/02/1000x450_Siri.jpg" alt="Siri asking What can I help you with" width="1000" height="450"  />

Bret Kinsella (editor of [voicebot.ai][10]) gave a keynote speech at the 2018 Smart Voice Summit which further confirmed the urgency for brands to create a voice strategy. Advances in technology (machine learning can now rival human accuracy) and market readiness (16% of Americans own a smart speaker) create the ideal environment for brands to launch their voice app. According to Kinsella’s stats, currently 41% of consumers prefer voice to mobile apps or the web. The top reason given for this is because it is more convenient.

### Voice guidelines

**Amazon**

[Designing for voice:][11] clear guidelines on how they expect you to ‘design’ a voice experience.

**Google**

> A good UI also means validating user input and managing expectations in order to earn their trust and instil confidence.
  
> – Source, slightly creepy guidelines: [The Conversational UI and Why It Matters][12]

### Possible applications for voice

**Retail
  
** 
  
Customer support
  
Sales requests
  
Customer feedback

**Health Care**

Emergency assistance
  
Medical stations
  
Retirement homes

### And SEO?

Search engines use different methods to return the most relevant content for voice searches. Now is the time to start thinking about how to optimise your content for natural language search.

**Things to think about for returning the right results**

  * Intent 
      * How
      * What
      * Where
      * Best
      * etc
  * Environment 
      * At home
      * At work
      * On the go
      * Offline?
  * Device 
      * Smart speaker
      * Mobile
      * Tablet
      * Desktop PC
  * Machine learning (can now rival human accuracy) 
      * [AI][13]
      * [Google Rankbrain algorithm][14]

### Your content

With natural language voice search, understanding intent becomes even more important, and navigating the nuances is critical to success. The rise in more conversational search language is one of the main reasons voice search is on the rise.

When you’re optimising for voice search, you need to think about SEO differently. For instance, unlike typical search queries you do on your computer, voice search queries are longer than their text counterparts. They tend to be three to five (or more) keywords in length. This means you need to change the way you do keyword research and think about longer long-tail keywords.

Search queries also tend to specifically ask a question and typically use trigger words like who, how, what, where, best, where, why and when.

### Give the machines what they want

I have talked about the importance of structured data and semantics, all for good reason, it is one of the biggest contributors to being ranked in voice search queries. Schema will match the search intent with the content most relevant to the query.

  1. [Talesmith – schema and semantics][15]
  2. [3 invisible – but important – ways we made our website more SEO-friendly][16]

#### [Featured snippets][17] [help with mobile and voice search][16]

Mobile search traffic has surpassed desktop traffic worldwide. And with the growth in voice-activated digital assistants, more people are doing voice queries. In these cases, the traditional 10 blue links format doesn't work as well, making featured snippets an especially useful format.

Write content in a conversational manner, and think about natural-language processing. Build content that answers questions quickly. Make sure structured data markup is integrated into your website where appropriate.

When consumers are searching on their phone, Alexa or another device, your goal is to answer these questions with written content focused on long-tail topics as a part of a greater mix of content included on your site.

### Top tips: Use these structured data types

This will most likely soon be your bible: Schema.org Actions. Remember an action is intent.
  
<https://schema.org/docs/actions.html>

Actually, this should just be your startup page when you launch your browser:
  
<https://schema.org/docs/full.html>

### Summary (or tl;dr)

With a solid voice strategy that captures the essence of your brand principles and personality, you could begin to shape your content away from traditional single keyword-based queries, towards more bespoke long-tail, conversation-like interactions. The importance of structured data can not be stressed enough.
  
The US market is ready, and is gaining traction in the UK.

### Further reading

[Learning the basics of conversational UI with a UX designer for Amazon’s Alexa][18]
  
[How natural language processing has changed SEO][19]
  
[The best UX is no interface at all][20]

 [1]: https://www.ipsos.com/sites/default/files/ct/publication/documents/2018-01/ipsos_connect_techtracker_q4_2017.pdf
 [2]: https://news.sky.com/story/amazon-cleared-after-alexa-ad-triggers-cat-food-order-11249840
 [3]: https://www.theverge.com/circuitbreaker/2018/2/14/17012382/apple-homepod-white-ring-wooden-table-staining-issue-problem
 [4]: https://www.technologyreview.com/s/603278/should-an-amazon-echo-help-solve-a-murder/
 [5]: https://www.bbc.co.uk/news/technology-43325230
 [6]: https://thenextweb.com/facebook/2018/02/14/report-facebook-releasing-smart-speakers-july/
 [7]: https://www.blog.google/products/assistant/your-assistant-getting-better-on-google-home-and-your-phone/
 [8]: https://www.mark-making.com/the-internet-of-things/
 [9]: https://techcrunch.com/2017/11/08/voice-enabled-smart-speakers-to-reach-55-of-u-s-households-by-2022-says-report/
 [10]: https://www.voicebot.ai/the-voicebot-ai-team/
 [11]: https://developer.amazon.com/designing-for-voice/
 [12]: https://developers.google.com/actions/design/
 [13]: https://www.technologyreview.com/s/603672/whats-next-for-ai-home-assistants/
 [14]: https://searchengineland.com/faq-all-about-the-new-google-rankbrain-algorithm-234440
 [15]: https://www.mark-making.com/talesmith-schema-and-semantics/
 [16]: https://www.mark-making.com/schema-structured-data/
 [17]: https://blog.google/products/search/reintroduction-googles-featured-snippets/
 [18]: https://medium.freecodecamp.org/learning-the-basics-of-conversational-ui-with-a-ux-designer-for-amazons-alexa-c76c1908454b
 [19]: https://trackmaven.com/blog/natural-language-processing-changed-seo/
 [20]: https://css-tricks.com/best-ux-no-user-interface/